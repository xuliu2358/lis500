<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Overview: Teachable Machines</title>
    <link rel="stylesheet" href="stylepage.css">
</head>
<body>
    <header>
        <h1>Project Overview: Teachable Machines for Capybara, Cats, and Dogs</h1>
    </header>

    <nav class="vertical-nav">
        <ul>
            <li><a href="index1.html">Home</a></li>
            <li><a href="about.html">About Us</a></li>
            <li><a href="resources.html">Resources</a></li>
            <li><a href="techhero.html">Tech Hero</a></li>
            <li><a href="project statement.html">Project Statement</a></li>
            <li><a href="machine.html">Machines</a></li>
        </ul>
    </nav>

    <section>
        <h2>Project Overview---Full Version on Github</h2>
        <p>The project focuses on Teachable Machines open-sources which capable for recognizing and classifying images of cutie animals. What we used is called supervised learning models, this project aimed to develop a powerful and easy-to-use classification system. Our work is inspired by Joy Buolamwini's <i>Unmasking AI: My Mission to Protect What Is Human in a World of Machines</i>, which emphasizes the ethical, societal, and moral dimensions of AI development.</p>
        <p>This project not only addresses technical objectives like accuracy and efficiency but also embraces the broader goal of embedding fairness, transparency, and inclusivity into the AI development process. Buolamwini’s insights serve as a guiding framework, encouraging us to interrogate biases in data and design choices while aiming to build a system that uplifts rather than marginalizes.</p>
    </section>

    <section>
        <h2>How “Unmasking AI” and Other Mutual Affect Designs</h2>
        <h3>1. The Coded Gaze: Recognizing Bias in AI</h3>
        <p>J. Buolamwini shared an idea of the Coded Gaze to highlight how AI systems magnify the biases of developers and the datasets they're using for training and testing. In her book <i>Unmasking AI</i>, she shares a powerful personal experience with facial detection software that could not detect her face until she wore a white mask. This illustrates how imbalances in data can result in discriminatory outcomes, reinstating the urgent need for more inclusive and equitable AI systems.</p>
        <ul>
            <li>Capybara images predominantly depicted natural environments, raising concerns about misclassification in urban settings.</li>
            <li>Black-coated animals (both cats and dogs) were underrepresented, leading to lower accuracy in their classification due to lighting challenges.</li>
        </ul>

        <h3>2. Who Shapes AI? Power Dynamics and Representation</h3>
        <p>A central argument in <i>Unmasking AI</i> is that AI systems are not neutral—they are shaped by the priorities, values, and assumptions of their creators and the institutions behind them. Buolamwini emphasizes the importance of diverse perspectives in AI development to prevent reinforcing existing power imbalances.</p>

        <h3>3. Transparency as Accountability</h3>
        <p>A user-friendly interface was provided with all source code attributes to model, train, test, and execute with a comprehensive accuracy dashboard, allowing users to test the teachable machine and view its confidence levels for each classification.</p>
    </section>

    <section>
        <h2>Conclusion</h2>
        <p>Joy Buolamwini’s <i>Unmasking AI</i> provides a powerful framework for ethical AI development. By embedding its principles—recognizing bias, fostering inclusivity, prioritizing transparency, embracing intersectionality, and pursuing algorithmic justice—into our teachable machine project, we sought to go beyond technical excellence and contribute to the broader conversation about AI’s societal impact.</p>
        <p>The project serves as a reminder that AI development is a moral endeavor, not just a technical challenge. As Buolamwini asserts, “AI systems are mirrors of power.” Our work reflects a commitment to challenging that power, ensuring that AI systems uplift rather than marginalize. This is a small but meaningful step toward a future where technology serves humanity equitably and ethically.</p>
    </section>

    <footer>
        <p>&copy; 2024 Jiao Jin, Yankaiqi Li and Xu Liu's Projects. </p>
    </footer>
</body>
</html>
